{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 7 â€“ Table Fundamentals\n",
    "\n",
    "### Spark 010, Spring 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run me\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Containment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful Python **operator** is the `in` keyword, which checks if the first value is present within the second value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'berkeley' in 'uc berkeley'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'stanford' in 'uc berkeley'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'berkeley' in 'UC BERKELEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Indexing\n",
    "\n",
    "We can now use this Boolean array to index the entries in the original array where the condition specified returned `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_or_higher = np.array([86.9, 83.9, 88.5, 87.2, 84.4])\n",
    "above_85_hs = hs_or_higher > 85\n",
    "above_85_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_or_higher[above_85_hs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can index the entries which returned `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_or_higher[~above_85_hs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames (or tables) allow us to organize data in a systematic and easy-to-work-with way. Each table consists of **columns**, which represent variables, and **rows**, which represent one individual or observation.\n",
    "\n",
    "Most of our datasets will be stored in `.csv` files (CSV stands for \"Comma Separated Values\"), which we will _import_ into our notebook using the `pd.read_csv(...)` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load in the same dataset of California public universities from the first lecture by passing in the _filepath_ string corresponding to where our `.csv` file is in our computer's folder structure. (Don't worry, you don't need to know how this works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = pd.read_csv('data/cal_unis.csv')\n",
    "schools.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things we often want to know about our data or table is how big it is. We can use the usual `len` function we learned about already to get the number of rows, or we can use the `.shape` method to return the dimensions of our table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools.shape[0] # Find the number of rows in the `schools` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools.shape[1] # Find the number columns in the `schools` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the first few Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a subset of the first five schools in the table for illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_schools = schools.head(5) #display the first five rows of the table\n",
    "some_schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_schools = schools.tail(3) #display the last three rows of the table\n",
    "other_schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column in a DataFrame is an **array**, which is useful when we want to perform arithmetic on entire columns. We can extract a particular column with the `df.loc[...]` method. Note that when we talk about DataFrame methods in the `pandas` library, we will use `df` to refer to the name of a general DataFrame. When using these methods, remember to replace `df` is the name of the table you're working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Columns and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_schools.loc[:,'City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_schools.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_schools.loc[2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Check 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.read_csv('data/us-state-capitals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should we pass into `.loc[]` in order to get the latitudes of each state capital as an array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.loc[...].values # Replace the three dots with your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.loc` and `drop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common workflow when working with tables is to **import** the table, **identify** relevant columns, and then make a **new table** with only the columns we want to work with. The `.loc()` and `.drop()` table methods allow us to do just that. Notice how both methods achieve the same result, just by slightly different means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we only want to display the columns `Name` and `Enrollment`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_schools.loc[:,['Name', 'Enrollment']] # Select only the columns 'Name' and 'Enrollment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do this by specifying the columns labels we *don't* want to display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_schools.drop(columns = ['Founded', 'County', 'Institution', 'City']) # Drop columns so that you are left with only 'Name' and 'Enrollment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember** that _the above_ table methods return a **new table**, so the original `some_schools` table is not modified!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we might want to do with a table is add additional columns that provide additional tables. We can use the `df.insert()` method to add columns to an existing table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the nicknames for each of the five schools (Cal, UCD, UCI, UCLA, UCM)\n",
    "some_schools.insert(1,'Nickname',['Cal', 'UCD', 'UCI', 'UCLA', 'UCM'])\n",
    "some_schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two columns to `some_schools`: one with the nickname for the school and the other for how old the school is\n",
    "some_schools.insert(5,'Years Old', 2022 - some_schools.loc[:,'Founded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the method `df.insert()` *does* change the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tables from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `pd.DataFrame()` to make an entirely new table from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pd.DataFrame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.DataFrame({'State':['California', 'New York', 'Florida', 'Texas', 'Pennsylvania'],\n",
    "                       'Code':['CA', 'NY', 'FL', 'TX', 'PA'],\n",
    "                       'Population':[39.3, 19.3, 21.7, 29.3, 12.8]})\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Check 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the table `states`, fill in the blanks in the second cell to create a new table that corresponds to the following table:\n",
    "\n",
    "| State | Code | FedVote |\n",
    "| --- | --- | --- |\n",
    "| California | CA | D|\n",
    "| New York | NY | D |\n",
    "| Florida | FL | R |\n",
    "| Texas | TX | R |\n",
    "| Pennsylvania | PA | D |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the ... to drop the approprate column\n",
    "states = states.drop(columns = ...)\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the ... to insert the appropriate column\n",
    "states.insert(...)\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
